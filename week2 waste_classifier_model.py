# -*- coding: utf-8 -*-
"""waste_classifier_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17vT7A_3jgp0ruUptRdXSIjIxI3MrQ8ny
"""

!pip install opendatasets

import opendatasets as od

data = od.download("https://www.kaggle.com/datasets/sumn2u/garbage-classification-v2")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import matplotlib.pyplot as plt

print("TensorFlow version:", tf.__version__)

!ls /content/dataset
!ls /content/dataset/garbage-dataset

train_path = '/content/dataset/garbage-dataset'

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

train_gen = train_datagen.flow_from_directory(
    train_path,
    target_size=(128,128),
    batch_size=32,
    subset='training'
)

val_gen = train_datagen.flow_from_directory(
    train_path,
    target_size=(128,128),
    batch_size=32,
    subset='validation'
)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),

    Dense(train_gen.num_classes, activation='softmax')  # matches your dataset’s 10 classes
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Display model summary
model.summary()

history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10
)

model.save('waste_classifier_model.h5')
print("✅ Model saved successfully!")

import matplotlib.pyplot as plt

# Accuracy Graph
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Loss Graph
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

import numpy as np
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt

# Pick any one image from your dataset folder to test
img_path = '/content/dataset/garbage-dataset/clothes/clothes_1.jpg'   # you can change this file name

# Load and preprocess the image
img = image.load_img(img_path, target_size=(128,128))
img_array = image.img_to_array(img)/255.0
img_array = np.expand_dims(img_array, axis=0)

# Make prediction
prediction = model.predict(img_array)
predicted_class = list(train_gen.class_indices.keys())[np.argmax(prediction)]

# Show the image and result
plt.imshow(image.load_img(img_path))
plt.axis('off')
plt.title(f'Predicted: {predicted_class}', fontsize=14)
plt.show()

print("✅ Predicted class:", predicted_class)
print("Image array shape:", img_array.shape)

from google.colab import files
files.download('waste_classifier_model.h5')

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Recreate the same model structure
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),

    Dense(10, activation='softmax')  # 10 classes in your dataset
])

# Compile it again
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input

# Recreate the same model structure, using Input layer explicitly
model = Sequential([
    Input(shape=(128, 128, 3)), # Explicitly define the input layer
    Conv2D(32, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),

    Dense(10, activation='softmax')  # 10 classes in your dataset
])

# Compile it again
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()